{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Project_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2322f27a"
      },
      "source": [
        "# Turn on multi-threading on your computer for faster calculation \n",
        "%env OMP_NUM_THREADS = 10"
      ],
      "id": "2322f27a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cae53ea"
      },
      "source": [
        "# importing misceallenous libraries\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import timeit\n",
        "import string\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "from dateutil.parser import parse\n",
        "import copy\n",
        "import math\n",
        "\n",
        "# importing libraries for data handling and analysis\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "from openpyxl import load_workbook\n",
        "import numpy as np\n",
        "from scipy.stats import norm, skew\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "from pandas import Series\n",
        "from numpy.random import randn\n",
        "import statsmodels.api as sm\n",
        "import random\n",
        "from scipy import stats\n",
        "\n",
        "# importing libraries for data visualisations\n",
        "import seaborn as sns\n",
        "import matplotlib as mp\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "color = sns.color_palette()\n",
        "from IPython.display import display\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# Standard plotly imports\n",
        "# import chart_studio.plotly as chpy\n",
        "import plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "#py.initnotebookmode(connected=True) # this code, allow us to work with offline plotly version\n",
        "# Using plotly + cufflinks in offline mode\n",
        "import cufflinks as cf\n",
        "cf.set_config_file(offline=True)\n",
        "import cufflinks\n",
        "cufflinks.go_offline(connected=True)\n",
        "\n",
        "# sklearn modules for preprocessing\n",
        "import sklearn as sk\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "# from imblearn.over_sampling import SMOTE  # SMOTE\n",
        "# sklearn modules for ML model selection\n",
        "from sklearn.model_selection import train_test_split  # import 'train_test_split'\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, make_scorer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Libraries for data modelling\n",
        "from sklearn import svm, tree, linear_model, neighbors\n",
        "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Common sklearn Model Helpers\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# sklearn modules for performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
        "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "id": "3cae53ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae9f8118"
      },
      "source": [
        "master = pd.read_csv('Master - Copy.csv')\n",
        "train_def = pd.read_csv('Train.csv')\n",
        "predict = pd.read_csv('Predict.csv')\n",
        "\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None\n"
      ],
      "id": "ae9f8118",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb912cc1"
      },
      "source": [
        "master.shape"
      ],
      "id": "fb912cc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7bc751a"
      },
      "source": [
        "master.info() # Checking what kinds of data we have "
      ],
      "id": "e7bc751a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8badfe95"
      },
      "source": [
        "master.describe() # Count=1470 for all, hence no missing value"
      ],
      "id": "8badfe95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63953f52"
      },
      "source": [
        "master.isna().sum()    # check for missing values for surity"
      ],
      "id": "63953f52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a39e219b"
      },
      "source": [
        "master.columns.to_series().groupby(master.dtypes).groups"
      ],
      "id": "a39e219b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llF-nIf7Fa24"
      },
      "source": [
        "# Define a dictionary for the target mapping\n",
        "target_map = {'Yes':1, 'No':0}\n",
        "# Use the pandas apply method to numerically encode our attrition target variable\n",
        "master[\"Attrition\"] = master[\"Attrition\"].apply(lambda x: target_map[x])"
      ],
      "id": "llF-nIf7Fa24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4026772d"
      },
      "source": [
        "train_def.hist(figsize=(20,20))\n",
        "plt.show()"
      ],
      "id": "4026772d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTaH4rzqFH75"
      },
      "source": [
        "corr = master.corr()\n",
        "corr['Attrition'].sort_values(ascending=False)"
      ],
      "id": "HTaH4rzqFH75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmwOA89FFp4H"
      },
      "source": [
        "# Heatmap for first n numerical features that correlate with target the most \n",
        "n = 50\n",
        "plt.figure(figsize = (35,12))\n",
        "sns.set(font_scale=0.8)\n",
        "sns.heatmap(master[corr.nlargest(n, 'Attrition').index].corr(), \n",
        "            annot = True, \n",
        "            fmt = '.02f', \n",
        "            square = True, \n",
        "            cbar = False,).set(title = \"Heatmap of Highly correlated values\")"
      ],
      "id": "zmwOA89FFp4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368d734e"
      },
      "source": [
        "#Checking unique values in each column\n",
        "\n",
        "for col in list(master):\n",
        "    print(col)\n",
        "    print(master[col].unique())"
      ],
      "id": "368d734e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "979457b5"
      },
      "source": [
        " #Moving Employee Number to 1st column\n",
        "master = master[['EmployeeNumber'] + [ col for col in master.columns if col != 'EmployeeNumber']]\n",
        "master.head()"
      ],
      "id": "979457b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae1f0037"
      },
      "source": [
        "## Creating a Function to Distribute the Age\n",
        "def func(x):\n",
        "    if(x >=20 and x<30 ):\n",
        "        return 1\n",
        "    elif(x>=30 and x<40):\n",
        "        return 2\n",
        "    elif(x>=40 and x<50):\n",
        "        return 3\n",
        "    elif(x>=50 and x<60):\n",
        "        return 4\n",
        "    elif(x>=60 and x<=80):\n",
        "        return 5\n",
        "    \n",
        "master['Age'] = master['Age'].apply(func)\n",
        "# master"
      ],
      "id": "ae1f0037",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfeWQfIii4Q"
      },
      "source": [
        "## Creating a Function to Distribute the Years at company\n",
        "def func(x):\n",
        "    if(x >=1 and x<6 ):\n",
        "        return 1\n",
        "    elif(x>=6 and x<11):\n",
        "        return 2\n",
        "    elif(x>=11 and x<21):\n",
        "        return 3\n",
        "    elif(x>=21 and x<80):\n",
        "        return 4\n",
        "    \n",
        "master['YearsAtCompany'] = master['YearsAtCompany'].apply(func)"
      ],
      "id": "nmfeWQfIii4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e29ca37"
      },
      "source": [
        "master['Attrition'] = master['Attrition'].astype('category')\n",
        "master['Age'] = master['Age'].astype('category')\n",
        "master['Education'] = master['Education'].astype('category')\n",
        "master['EnvironmentSatisfaction'] = master['EnvironmentSatisfaction'].astype('category')\n",
        "master['JobInvolvement'] = master['JobInvolvement'].astype('category')\n",
        "master['JobLevel'] = master['JobLevel'].astype('category')\n",
        "master['JobSatisfaction'] = master['JobSatisfaction'].astype('category')\n",
        "master['PerformanceRating'] = master['PerformanceRating'].astype('category')\n",
        "master['RelationshipSatisfaction'] = master['RelationshipSatisfaction'].astype('category')\n",
        "master['StockOptionLevel'] = master['StockOptionLevel'].astype('category')\n",
        "master['WorkLifeBalance'] = master['WorkLifeBalance'].astype('category')\n",
        "master['YearsAtCompany'] = master['YearsAtCompany'].astype('category')\n",
        "master['PromotedInCurrentRole'] = master['PromotedInCurrentRole'].astype('category')\n",
        "master['RoleChangeWithinCompany'] = master['RoleChangeWithinCompany'].astype('category')"
      ],
      "id": "0e29ca37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39ba1e84"
      },
      "source": [
        "Attrition = master['Attrition']\n",
        "df = copy.deepcopy(master).drop(['Attrition', 'EmployeeCount', 'Over18', 'StandardHours' ], axis=1)\n",
        "df.shape"
      ],
      "id": "39ba1e84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "f40e023d"
      },
      "source": [
        "# creating dummy variables for non-numbers (\"one hot encoding\")\n",
        "df = pd.get_dummies(df, columns = df.select_dtypes(exclude=['int64','float64']).columns)\n",
        "df[df[\"EmployeeNumber\"] == 137]"
      ],
      "id": "f40e023d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9318219f"
      },
      "source": [
        "df.shape"
      ],
      "id": "9318219f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0706a8b4"
      },
      "source": [
        "df['Attrition'] = Attrition"
      ],
      "id": "0706a8b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44bc105f"
      },
      "source": [
        "df.shape"
      ],
      "id": "44bc105f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5364d38f"
      },
      "source": [
        "ID = train_def['EmployeeNumber']"
      ],
      "id": "5364d38f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f2f89b3"
      },
      "source": [
        "# splitting train and test data\n",
        "train = df.iloc[:len(ID), :].reset_index(drop=True)\n",
        "pred = df.iloc[len(train):, :].reset_index(drop=True)"
      ],
      "id": "9f2f89b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f62567b"
      },
      "source": [
        "print(train.shape)\n",
        "print(pred.shape)"
      ],
      "id": "3f62567b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "568fadda"
      },
      "source": [
        "y = train['Attrition']\n",
        "X = train.drop(['Attrition', 'EmployeeNumber'], axis = 1)"
      ],
      "id": "568fadda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45373281"
      },
      "source": [
        "X.shape"
      ],
      "id": "45373281",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "352e2198"
      },
      "source": [
        "# set a starting value (\"seed\") for the random number generator\n",
        "np.random.seed(77300)\n",
        "\n",
        "# split the data randomly into train and holdout\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 120, stratify=y)\n",
        " \n",
        "# Lets check the results\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "352e2198",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c15f7f6"
      },
      "source": [
        "y_test.head()"
      ],
      "id": "2c15f7f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ea3c664"
      },
      "source": [
        "# First we define a set of functions to compute the metrics of the model\n",
        "\n",
        "# ROC curve\n",
        "def plot_roc(y_test, y_pred):\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1, drop_intermediate = False)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "             lw=lw, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([-0.001, 1.001])\n",
        "    plt.ylim([-0.001, 1.001])\n",
        "    plt.xlabel('1-Specificity (False Negative Rate)')\n",
        "    plt.ylabel('Sensitivity (True Positive Rate)')\n",
        "    plt.title('ROC curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Confusion Matrix returns in the format: cm[0,0], cm[0,1], cm[1,0], cm[1,1]: tn, fp, fn, tp\n",
        "\n",
        "# Sensitivity\n",
        "def custom_sensitivity_score(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    return (tp/(tp+fn))\n",
        "\n",
        "# Specificity\n",
        "def custom_specificity_score(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    return (tn/(tn+fp))\n",
        "\n",
        "# Positive Predictive Value\n",
        "def custom_ppv_score(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    return (tp/(tp+fp))\n",
        "\n",
        "# Negative Predictive Value\n",
        "def custom_npv_score(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    return (tn/(tn+fn))\n",
        "\n",
        "# Accuracy\n",
        "def custom_accuracy_score(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
        "    return ((tn+tp)/(tn+tp+fn+fp))"
      ],
      "id": "2ea3c664",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37a27da0"
      },
      "source": [
        "# Select the threshold value \n",
        "class_threshold = 0.28"
      ],
      "id": "37a27da0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce9ead0"
      },
      "source": [
        "# Model №1: Logistic regression"
      ],
      "id": "7ce9ead0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9515b135"
      },
      "source": [
        "# define the model and call it classifier_LR\n",
        "classifier_LR = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# train classifier_LR on the training data\n",
        "classifier_LR.fit(X_train, y_train)\n",
        "\n",
        "# This is a regression, so it has coefficients -- lets see them\n",
        "# Note, there is no easy way to show significance, etc. with sklearn\n",
        "print('Intercept: ' + str(classifier_LR.intercept_))\n",
        "print('Coefficients (10 largest and 10 smallest') \n",
        "summary = pd.DataFrame([X_test.columns,classifier_LR.coef_[0]]).transpose().sort_values(by = 1, ascending = False)\n",
        "summary.columns = ['Variable','Coefficient']\n",
        "top10positive = summary.head(10) # 10 largest (by value)\n",
        "top10negative = summary.tail(10) # 10 smallest (by value)\n",
        "top10list=pd.DataFrame()\n",
        "top10list= top10list.append(pd.DataFrame(data = top10positive))\n",
        "top10list= top10list.append(pd.DataFrame(data = top10negative))\n",
        "top10list"
      ],
      "id": "9515b135",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c839d008"
      },
      "source": [
        "# Use the trained model to predict testing data\n",
        "\n",
        "y_pred_prob = classifier_LR.predict_proba(X_test)[:,1] # probabilities\n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # applying the threshold rule to classify\n",
        "\n",
        "print(y_pred_prob[0:5]) # first 5 probabilities \n",
        "print(y_pred[0:5]) # resultant predicted classification \n",
        "print(y_test[0:5]) # actual outcomes\n"
      ],
      "id": "c839d008",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "732bcac6"
      },
      "source": [
        "# Lets look at the model metrics \n",
        "print('Metrics of the logistic regression model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))\n"
      ],
      "id": "732bcac6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73e595c6"
      },
      "source": [
        "# Apply variable selection with Stepwise Recursive Feature Selection \n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "rfe = RFE(estimator=classifier_LR, n_features_to_select=85, step=1) # in this example we will select 20 variables; this number \"20\" is a hyperparameter to tune\n",
        "rfe.fit(X_train, y_train)\n",
        "ranking = rfe.ranking_.reshape(len(X_train.columns))\n",
        "\n",
        "# which 85 variables are in the model?\n",
        "pd.DataFrame([X_test.columns,ranking]).transpose().sort_values(1).head(30)\n"
      ],
      "id": "73e595c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec8d0a5e"
      },
      "source": [
        "# Train the model and call it classifier_LR_RFE \n",
        "classifier_LR_RFE = rfe.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained model to predict testing data\n",
        "y_pred_prob = classifier_LR_RFE.predict_proba(X_test)[:,1] # probabilities\n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "\n",
        "# Lets look at the model metrics after variable selection \n",
        "print('Metrics of the logistic regression model after variable selection: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))\n"
      ],
      "id": "ec8d0a5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7f1fbf0"
      },
      "source": [
        "# Method №2: Classification and Regression Tree, CART (aka \"decision tree\")"
      ],
      "id": "c7f1fbf0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c281d4b"
      },
      "source": [
        "# Define a CART model and call it classifier_DT\n",
        "classifier_DT = DecisionTreeClassifier(max_leaf_nodes = 5, random_state=77300) # random_state -- is same as random seed, neede to get the same result every time we rerun\n",
        "\n",
        "# Train the model classifier_DT on the training data\n",
        "classifier_DT.fit(X_train, y_train)\n",
        "\n",
        "#  Use the trained model to predict testing data\n",
        "y_pred_prob = classifier_DT.predict_proba(X_test)[:,1] # probabilities \n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "print(y_pred_prob[0:5]) # first 5 probabilities \n",
        "print(y_pred[0:5]) # resultant predicted classification \n",
        "print(y_test[0:5]) # actual outcomes\n",
        "\n",
        "# WOW -- the CART model made no mistakes on the first 5 customers! \n"
      ],
      "id": "1c281d4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c205021"
      },
      "source": [
        "# Visualizing the resultant tree\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "plt.figure(figsize=(40,20))\n",
        "tree.plot_tree(classifier_DT.fit(X_train, y_train), feature_names = X_train.columns, filled = True, \n",
        "               class_names = ['Not Retained', 'Retained'], rounded = True)\n",
        "print('CART tree with 5 leafs')\n"
      ],
      "id": "9c205021",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3abbcf85"
      },
      "source": [
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the CART model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
      ],
      "id": "3abbcf85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49d6cd09"
      },
      "source": [
        "# Hyper-parameter tuning. A CART model has multiple hyper-parameters, for instance:\n",
        "# -- max number of leaves on a tree, \n",
        "# -- min number of datapoints at a leaf\n",
        "# -- min number of datapoints to create a split\n",
        "# and so on\n",
        "\n",
        "DecisionTreeClassifier() # display what those hyper-parameters are and their default values"
      ],
      "id": "49d6cd09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3556358b"
      },
      "source": [
        "# Tuning hyper-parameter max_leaf_nodes\n",
        "\n",
        "n_max_leaf_nodes = range(5,40) # Lets train the models with 5, 6, 7, ... 40 leafs\n",
        "\n",
        "# for each model calculate AUC for testing \n",
        "array = []\n",
        "for n in n_max_leaf_nodes:\n",
        "    \n",
        "    classifier_DT = tree.DecisionTreeClassifier(criterion = 'gini', max_leaf_nodes = n)\n",
        "    classifier_DT = classifier_DT.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred_prob = classifier_DT.predict_proba(X_test)[:,1]   \n",
        "    y_pred = np.where(y_pred_prob > class_threshold, 1, 0)\n",
        "\n",
        "    array.append([n,roc_auc_score(y_test, y_pred_prob)])\n",
        "\n",
        "# plot the testing set AUCs\n",
        "array = pd.DataFrame(array)\n",
        "plt.scatter(array[0],array[1])\n",
        "\n",
        "# now for each model calculate AUC on training \n",
        "array = []\n",
        "for n in n_max_leaf_nodes:\n",
        "\n",
        "    classifier_DT = tree.DecisionTreeClassifier(criterion = 'gini', max_leaf_nodes = n)\n",
        "    classifier_DT = classifier_DT.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred_prob = classifier_DT.predict_proba(X_train)[:,1] \n",
        "    y_pred = np.where(y_pred_prob > class_threshold, 1, 0)\n",
        "\n",
        "    array.append([n,roc_auc_score(y_train, y_pred_prob)])\n",
        "\n",
        "# plot the training set AUCs\n",
        "array = pd.DataFrame(array)\n",
        "plt.scatter(array[0],array[1])\n",
        "\n",
        "# label the axes on the plot\n",
        "plt.xlabel('Hyper-parameter max_leaf_nodes')\n",
        "plt.ylabel('AUC')\n",
        "\n",
        "# add the legend\n",
        "plt.legend(['Testing set','Training set'])\n"
      ],
      "id": "3556358b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f706fcb"
      },
      "source": [
        "# lets train the model with 8 leafs\n",
        "classifier_DT = tree.DecisionTreeClassifier(criterion = 'gini', max_leaf_nodes = 8)\n",
        "classifier_DT = classifier_DT.fit(X_train, y_train)\n",
        "\n",
        "# obtain its predictions\n",
        "y_pred_prob = classifier_DT.predict_proba(X_test)[:,1]   \n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0)\n",
        "\n",
        "# calclate and print the AUC\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
      ],
      "id": "9f706fcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8c6faa"
      },
      "source": [
        "# Method №3: Random Forest"
      ],
      "id": "db8c6faa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40544ab2"
      },
      "source": [
        "# Define a random forest model and call it classifier_RF\n",
        "classifier_RF = RandomForestClassifier(random_state=77300) # recall what random_state mean\n",
        "\n",
        "# Train the model classifier_RF on the training data\n",
        "classifier_RF.fit(X_train, y_train)\n",
        "\n",
        "# A random forest model has many hyper-parameters, for example::\n",
        "# -- the number of trees in the forest ensemble, \n",
        "# -- voting rules, \n",
        "# -- max number of leafs on each tree, \n",
        "# -- min number of datapoints at a leaf\n",
        "# and so on"
      ],
      "id": "40544ab2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ae94271f"
      },
      "source": [
        "# Use the trained model to predict testing data\n",
        "y_pred_prob = classifier_RF.predict_proba(X_test)[:,1] # probabilities \n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Random Forest model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))\n"
      ],
      "id": "ae94271f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d10f5cd0"
      },
      "source": [
        "# Hyper-parameter tuning (\"optimization\") using the function GridSearchCV for maximizing AUC\n",
        "score_func = make_scorer(roc_auc_score, greater_is_better=True)\n",
        "\n",
        "n_trees = [10, 50, 100, 150, 200, 250, 300, 350, 400, 500, 600, 700, 800, 900, 1000] # as an example, we will tune the \"numeber of trees\" hyper-parameter (n_trees) and we will consider values of 100, 200, ... 600 trees in the forest\n",
        "Grid_srch_parameters_list = [ [{'n_estimators':n_trees}] ] \n",
        "\n",
        "# we will apply a 5-fold cross-validation and call the resultant function \"grid_search\"\n",
        "grid_search = GridSearchCV(estimator = classifier_RF, cv = 5, param_grid = Grid_srch_parameters_list[0], scoring = score_func,\n",
        "                              return_train_score = True) \n",
        "\n",
        "# apply function grid_search to the training data, call the resultand best model grid_search_RF\n",
        "grid_search_RF = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# use the best model to predict the testing data\n",
        "y_pred_prob = grid_search_RF.predict_proba(X_test)[:,1] # probabilities  \n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "print('Optimized hyper-parameters:' + str(grid_search.best_params_))\n",
        "    \n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Random Forest model with the optimized hyper-parameter for the \"number of trees\": \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))\n"
      ],
      "id": "d10f5cd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048190c0"
      },
      "source": [
        "# Tree models do not have coefficients, but have easily-interpretable tree plots\n",
        "# But in tree ensembles (such as random forect) there is no point to look at individual trees\n",
        "\n",
        "# Useful intuition, however, can be obtained from the Feature Importance Plots\n",
        "\n",
        "# calculate feature importances\n",
        "importances = grid_search_RF.best_estimator_.feature_importances_ \n",
        "\n",
        "# plot them\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Decrease in Gini (recal, Gini = 2*AUC-1)')\n",
        "feature_importances = pd.Series(classifier_RF.feature_importances_, index=X_train.columns)\n",
        "feature_importances.nlargest(15).sort_values().plot(kind='barh', align='center')"
      ],
      "id": "048190c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea0e50b5"
      },
      "source": [
        "# Method №4: Gradient Boosting Machine"
      ],
      "id": "ea0e50b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f306f69"
      },
      "source": [
        "# Define the gradient boosting machine model and call it classifier_GBM\n",
        "classifier_GBM = GradientBoostingClassifier(random_state=77300)\n",
        "\n",
        "# Train the model classifier_GBM on the training data\n",
        "classifier_GBM.fit(X_train, y_train)\n",
        "\n",
        "# A gradient boosting model has many hyper-parameters, for example::\n",
        "# -- the number of trees in the forest ensemble, \n",
        "# -- speed of boosting (\"learning rate\", \"decay rate\"), \n",
        "# -- max number of leafs on each tree, \n",
        "# -- min number of datapoints at a leaf\n",
        "# and so on\n"
      ],
      "id": "9f306f69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8212142"
      },
      "source": [
        "# Use the trained model to predict testing data\n",
        "y_pred_prob = classifier_GBM.predict_proba(X_test)[:,1] # probabilities \n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Gradient Boosting Machine model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
      ],
      "id": "a8212142",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d84857e"
      },
      "source": [
        "# Hyper-parameter tuning (\"optimization\") using the function GridSearchCV for maximizing AUC\n",
        "score_func = make_scorer(roc_auc_score, greater_is_better=True)\n",
        "\n",
        "# as an example, we will tune two parameters\n",
        "n_trees = [100, 200, 300, 400, 500, 600] # first, the \"numeber of trees\" hyper-parameter (n_trees) and we will consider values of 100, 200, ... 600 trees in the forest\n",
        "learning_rates = [0.01, 0.05, 0.1, 0.5, 0.8] # second, speed of boosting (\"learning rate\") and we will use two values 0.01 и 0.1\n",
        "\n",
        "Grid_srch_parameters_list = [ [{'n_estimators':n_trees, 'learning_rate': learning_rates}] ] \n",
        "\n",
        "# we will apply a 5-fold cross-validation and call the resultant function \"grid_search\"\n",
        "grid_search = GridSearchCV(estimator = classifier_GBM, cv = 5, param_grid = Grid_srch_parameters_list[0], scoring = score_func,\n",
        "                              return_train_score = True) \n",
        "\n",
        "# # apply function grid_search to the training data, call the resultant best model grid_search_GBM\n",
        "grid_search_GBM = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# use the best model to predict the testing data \n",
        "y_pred_prob = grid_search_GBM.predict_proba(X_test)[:,1] # probabilities\n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "print('Optimized hyper-parameters:' + str(grid_search.best_params_))\n",
        "\n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Gradient Boosting Machine model with the optimized hyper-parameters\": \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))\n"
      ],
      "id": "4d84857e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "432382d3"
      },
      "source": [
        "# Method №5: Support Vector Machines"
      ],
      "id": "432382d3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faf3d7e3"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "svm_estimators = []\n",
        "svm_estimators.append(('standardize', StandardScaler())) # scale the data\n",
        "svm_estimators.append(('svm', svm.SVC(probability=True))) # define SVM with probabilities (recall, SVM be default does not predict probabilities)\n",
        "     \n",
        "# Define the support vectors machine model and call it classifier_SVM\n",
        "Classifier_SVM = Pipeline(svm_estimators, verbose=False)\n",
        "\n",
        "# Train the model classifier_SVM on the training data\n",
        "Classifier_SVM.fit(X_train, y_train)"
      ],
      "id": "faf3d7e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be653235"
      },
      "source": [
        "# use the fitted model to predict the testing data \n",
        "y_pred_prob = Classifier_SVM.predict_proba(X_test)[:,1] # probabilities\n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Support Vector Machines model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
      ],
      "id": "be653235",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14dd91c1"
      },
      "source": [
        "# Method №6: Artificial Neural Networks (\"Deep Learning\") with Tensor Flow"
      ],
      "id": "14dd91c1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507b912e"
      },
      "source": [
        "# !pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n"
      ],
      "id": "507b912e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ec4ce8"
      },
      "source": [
        "# Define the architecture and optimization metrics for the network\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(128,  activation=\"relu\", name=\"hidden-dense-128-layer-1\"),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation=\"relu\", name=\"hidden-dense-64-layer-2\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid', name=\"output-layer\"),\n",
        "    ])\n",
        "    adam = tf.keras.optimizers.Adam()\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "nn_estimators = []\n",
        "nn_estimators.append(('standardize', StandardScaler())) #scale the data\n",
        "nn_estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=30, batch_size=128, validation_split=0.2))) # compile the model\n",
        "\n",
        "# Define the TensorFlow Neural Network model and call it classifier_TF_NN\n",
        "Classifier_TF_NN = Pipeline(nn_estimators, verbose=False)\n",
        "\n",
        "# Train the model classifier_SVM on the training data\n",
        "Classifier_TF_NN.fit(X_train, y_train)"
      ],
      "id": "90ec4ce8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9898f5b"
      },
      "source": [
        "# use the fitted model to predict the testing data \n",
        "y_pred_prob = Classifier_TF_NN.predict_proba(X_test)[:,1] # probabilities\n",
        "y_pred = np.where(y_pred_prob > class_threshold, 1, 0) # classification\n",
        "\n",
        "# Lets look at the model metrics\n",
        "\n",
        "print('Metrics of the Tensor Flow Neural Network model: \\n')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix: \\n\" + str(cm))\n",
        "\n",
        "print(\"                                   Accuracy: \" + str(custom_accuracy_score(y_test, y_pred))) \n",
        "print(\"                   SENSITIVITY (aka RECALL): \" + str(custom_sensitivity_score(y_test, y_pred)))\n",
        "print(\"                 SPECIFICITY (aka FALL-OUT): \" + str(custom_specificity_score(y_test, y_pred)))\n",
        "print(\" POSITIVE PREDICTIVE VALUE, (aka PRECISION): \" + str(custom_ppv_score(y_test, y_pred)))\n",
        "print(\"                 NEGATIVE PREDICTIVE VALUE): \" + str(custom_npv_score(y_test, y_pred)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob)\n",
        "print(\" AUC: \" + str(roc_auc_score(y_test, y_pred_prob)))"
      ],
      "id": "f9898f5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b7404b9"
      },
      "source": [
        "# Prediction"
      ],
      "id": "2b7404b9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51d67bab"
      },
      "source": [
        "pred.shape"
      ],
      "id": "51d67bab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac442817"
      },
      "source": [
        "pred_ID = pred['EmployeeNumber']\n",
        "pred_churn = pred['Attrition']\n",
        "X_pred = pred.drop(columns=['Attrition', 'EmployeeNumber'], axis = 1).copy()"
      ],
      "id": "ac442817",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adde27be"
      },
      "source": [
        "# Since the Logistic Regression model with optimized hyper-parameters obtained the higest AUC, lets take that\n",
        "y_pred_prob_LR = classifier_LR_RFE.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_LR = np.where(y_pred_prob_LR > class_threshold, 1, 0) # classification \n",
        "# CART\n",
        "y_pred_prob_CART = classifier_DT.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_CART = np.where(y_pred_prob_CART > class_threshold, 1, 0) # classification \n",
        "# RF\n",
        "y_pred_prob_RF = classifier_RF.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_RF = np.where(y_pred_prob_RF > class_threshold, 1, 0) # classification \n",
        "# GBM\n",
        "y_pred_prob_GBM = classifier_GBM.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_GBM = np.where(y_pred_prob_GBM > class_threshold, 1, 0) # classification \n",
        "# SVM\n",
        "y_pred_prob_SVM = Classifier_SVM.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_SVM = np.where(y_pred_prob_SVM > class_threshold, 1, 0) # classification \n",
        "# TF\n",
        "y_pred_prob_TF = Classifier_TF_NN.predict_proba(X_pred)[:,1] # probabilities\n",
        "y_pred_TF = np.where(y_pred_prob_TF > class_threshold, 1, 0) # classification\n",
        "\n",
        "\n"
      ],
      "id": "adde27be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99e345c0"
      },
      "source": [
        "# Lets add the ID column to know \"who is who\"\n",
        "Prediction = pd.DataFrame(data={\"EmployeeNumber\": pred_ID,\"Probablity of Churn LR\":y_pred_prob_LR, \"Churn_LR\":y_pred_LR})"
      ],
      "id": "99e345c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318be583"
      },
      "source": [
        "pred_map = {1:'Yes', 0:'No'}\n",
        "# Use the pandas apply method to numerically encode our attrition target variable\n",
        "Prediction[\"Churn_LR\"] = Prediction[\"Churn_LR\"].apply(lambda x: pred_map[x])"
      ],
      "id": "318be583",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80535640"
      },
      "source": [
        "# Export the predictions into a CSV file\n",
        "Prediction.to_csv(\"Predicted Churn Model.csv\",sep = ',')"
      ],
      "id": "80535640",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "028cb35b"
      },
      "source": [
        ""
      ],
      "id": "028cb35b",
      "execution_count": null,
      "outputs": []
    }
  ]
}